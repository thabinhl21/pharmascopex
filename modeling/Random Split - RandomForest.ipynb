{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f39abd",
   "metadata": {},
   "source": [
    "# Notebook for Feature Engineering\n",
    "\n",
    "This notebook will contain a few steps to get the data ready for model training\n",
    "\n",
    "1. Data Cleaning (removing nulls, and other bad data)\n",
    "2. Feature Engineering (creating target features AUC+IC50)\n",
    "3. Creating Train Test Splits (including leave out drugs and leave out cell lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load in the merged dataframe, containing GDSC1, GDSC2, and cell line metadata\n",
    "gdsc_merged = pd.read_csv(\"../GDSC1and2_w_CellLineData.csv\")\n",
    "df = gdsc_merged\n",
    "gdsc_merged.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc_merged[gdsc_merged['DRUG_NAME'] == 'Etoposide']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25254a",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e667ad3",
   "metadata": {},
   "source": [
    "## Creation of Interaction Term IC50 + AUC\n",
    "\n",
    "In this segment we create sensitivity, disagreement and weighted averages for these terms. The goal is to have two metric targets and be able to train with either a dual output approach or a singlet output with weighted averages. I'll let the training team decided which to use or go with the one with better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[[\"z_LN_IC50\", \"z_AUC\"]] = scaler.fit_transform(df[[\"LN_IC50\", \"AUC\"]])\n",
    "\n",
    "# For interpretability: low LN_IC50 = sensitive, low AUC = sensitive\n",
    "df[\"z_IC50_sens\"] = df[\"z_LN_IC50\"]\n",
    "\n",
    "\n",
    "# Sensitivity (average of both)\n",
    "df[\"sensitivity\"] = (df[\"z_IC50_sens\"] + df[\"z_AUC\"]) / 2\n",
    "\n",
    "# Disagreement (difference between metrics)\n",
    "df[\"disagreement\"] = df[\"z_AUC\"] - df[\"z_IC50_sens\"]\n",
    "\n",
    "\n",
    "# Weighted averages of both metrics for different α\n",
    "alphas = [0.25, 0.5, 0.75]\n",
    "for a in alphas:\n",
    "    df[f\"y_weighted_{a}\"] = a * df[\"z_IC50_sens\"] + (1 - a) * df[\"z_AUC\"]\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697de1f",
   "metadata": {},
   "source": [
    "## Tissue Descriptors\n",
    "\n",
    "Lets focus on using only Tissue Descriptor 1 \"GDSC_Tissue_descriptor_1\". I would rather lean on the larger sample size of each bin within Tissue Descriptor 1 for ease/simplicity. I think there is a good argument for usind Tissue descriptor 2 for personalized medicine and specific drug discovery but its not worth it for now. We can't do a simple bootstrapping method to bring up categories with 5 samples up to 60 without creating significant bias. Tissue Descriptor 1 still has imbalances but the effects won't be as severe. It would be reasonable to combine oversampling and undersampling in this case though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86087ea",
   "metadata": {},
   "source": [
    "## Data Splits for Model Training\n",
    "1\n",
    "Random splits: This approach is also called Mixed-Set in [8, 39], and it is generally the least challenging, leading to the highest observed performance scores. In this scenario, a randomly selected subset of drug-cell line pairs is excluded from the training set and used as the test set. This train-test Splitting Strategy quantifies how accurate a model is in filling the gaps in a drug-cell lines matrix containing some unobserved values. Practically, this would correspond to filling a non-exhaustive screening on a panel of otherwise known cell lines and drugs. In this scenario, the model is not evaluated in terms of its ability to generalize to cell lines or drugs for which we completely lack drug response measurements.\n",
    "\n",
    "2\n",
    "Unseen cell lines: In this case, the train and test splits are made by ensuring that the cell lines in the training set are not present in the test. The test set is constructed by randomly selecting a subset of cell lines and all of their IC50 values from the entire dataset. To achieve high performance scores in this validation, the models need to be able to generalize to unseen cell lines. With respect to the Random Splits, this therefore increases the difficulty of the prediction task.\n",
    "\n",
    "3\n",
    "Unseen drugs: The train and test splits are made to ensure that the drugs that appear in the test set are not present in the training set. To perform well in this setting, the model must be able to generalize well to completely unseen drugs.\n",
    "\n",
    "4\n",
    "Unseen cell line-drug pairs: This is the most stringent validation setting. In this case, the training and test splits are built to ensure that each of the cell lines and drugs present in the test set are both absent from the training set. This setting therefore evaluates the ability of the model to generalize at the same time to unseen drugs and cell lines, which should be the ultimate goal of the cancer drug sensitivity prediction field. However, until now, generalization in this setting has been nearly impossible, and as such, it is infrequently utilized in evaluations [9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def random_split(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Completely random splitting.\n",
    "    \"\"\"\n",
    "    return train_test_split(df, test_size=test_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "def unseen_cell_lines_split(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits dataset so that cell lines in test are unseen in train.\n",
    "    \"\"\"\n",
    "    cell_lines = df['COSMIC_ID'].unique()\n",
    "    train_lines, test_lines = train_test_split(cell_lines, test_size=test_size, random_state=random_state)\n",
    "    train_df = df[df['COSMIC_ID'].isin(train_lines)]\n",
    "    test_df = df[df['COSMIC_ID'].isin(test_lines)]\n",
    "    return train_df, test_df\n",
    "\n",
    "def unseen_drugs_split(df, test_size=0.2, random_state=1):\n",
    "    \"\"\"\n",
    "    Splits dataset so that drugs in test are unseen in train.\n",
    "    \"\"\"\n",
    "    drugs = df['DRUG_ID'].unique()\n",
    "    train_drugs, test_drugs = train_test_split(drugs, test_size=test_size, random_state=random_state)\n",
    "    train_df = df[df['DRUG_ID'].isin(train_drugs)]\n",
    "    test_df = df[df['DRUG_ID'].isin(test_drugs)]\n",
    "    return train_df, test_df\n",
    "\n",
    "def unseen_cell_line_drug_pairs_split(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Creates disjoint sets of both drugs and cell lines.\n",
    "    Test set contains combinations of unseen drugs and unseen cell lines.\n",
    "    \"\"\"\n",
    "    drugs = df['DRUG_ID'].unique()\n",
    "    cell_lines = df['COSMIC_ID'].unique()\n",
    "\n",
    "    # Select subsets of drugs and cell lines for the test set\n",
    "    test_drugs = np.random.default_rng(random_state).choice(drugs, size=int(len(drugs) * test_size), replace=False)\n",
    "    test_cells = np.random.default_rng(random_state + 1).choice(cell_lines, size=int(len(cell_lines) * test_size), replace=False)\n",
    "\n",
    "    # Test = only pairs where BOTH drug and cell line are unseen\n",
    "    test_df = df[(df['DRUG_ID'].isin(test_drugs)) & (df['COSMIC_ID'].isin(test_cells))]\n",
    "\n",
    "    # Train = everything else (ensures no leakage)\n",
    "    train_df = df[~df.index.isin(test_df.index)]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = unseen_drugs_split(df)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ea513",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = set(test_df['DRUG_ID'].unique()) \n",
    "train = set(train_df['DRUG_ID'].unique())\n",
    "\n",
    "test.intersection(train)\n",
    "# Confirm no intersection in left out sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d085c9",
   "metadata": {},
   "source": [
    "## Training and Evaluation of the model\n",
    "\n",
    "We train Random Forest models using random split (mixed-set approach). This is the least challenging splitting strategy where random drug-cell line pairs are used for train/test split, allowing the model to learn from similar drugs and cell lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7d5ba",
   "metadata": {},
   "source": [
    "## Random Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261177f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split with random splitting\n",
    "train_df_random, test_df_random = random_split(df)\n",
    "\n",
    "print(f\"Training samples: {len(train_df_random)}\")\n",
    "print(f\"Test samples: {len(test_df_random)}\")\n",
    "print(f\"\\nSample overlap statistics:\")\n",
    "print(f\"Unique drugs in train: {train_df_random['DRUG_ID'].nunique()}\")\n",
    "print(f\"Unique drugs in test: {test_df_random['DRUG_ID'].nunique()}\")\n",
    "print(f\"Unique cell lines in train: {train_df_random['COSMIC_ID'].nunique()}\")\n",
    "print(f\"Unique cell lines in test: {test_df_random['COSMIC_ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43587f0",
   "metadata": {},
   "source": [
    "## Data encoding and feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82becc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Make explicit copies to avoid SettingWithCopyWarning\n",
    "# train_df_random = train_df_random.copy()\n",
    "# test_df_random = test_df_random.copy()\n",
    "\n",
    "# # Encode categorical variables (DRUG_ID and COSMIC_ID)\n",
    "# drug_encoder = LabelEncoder()\n",
    "# cell_encoder = LabelEncoder()\n",
    "\n",
    "# train_df_random['DRUG_ID_encoded'] = drug_encoder.fit_transform(train_df_random['DRUG_ID'])\n",
    "# train_df_random['COSMIC_ID_encoded'] = cell_encoder.fit_transform(train_df_random['COSMIC_ID'])\n",
    "\n",
    "# # For random split, test set should have mostly seen drugs/cells, so direct transform is usually safe\n",
    "# test_df_random['DRUG_ID_encoded'] = drug_encoder.transform(test_df_random['DRUG_ID'])\n",
    "# test_df_random['COSMIC_ID_encoded'] = cell_encoder.transform(test_df_random['COSMIC_ID'])\n",
    "\n",
    "# Prepare features and target\n",
    "X_train = train_df_random[['DRUG_ID', 'COSMIC_ID']]\n",
    "y_train = train_df_random['z_LN_IC50']\n",
    "\n",
    "X_test = test_df_random[['DRUG_ID', 'COSMIC_ID']]\n",
    "y_test = test_df_random['z_LN_IC50']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ba940",
   "metadata": {},
   "source": [
    "## Model Training for z_LN_IC50 Prediction\n",
    "\n",
    "Fitting modes to predict z_LN_IC50 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a3015",
   "metadata": {},
   "source": [
    "### Random Forest and Hyper Parameter Tuning for z_LN_IC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074db4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, 20, None]\n",
    "}\n",
    "\n",
    "# Create Random Forest model\n",
    "rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "print(\"Performing Grid Search for Random Forest hyperparameters...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"\\nBest parameters found:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest cross-validation RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")\n",
    "\n",
    "# Use the best model\n",
    "rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, y_train_pred_rf))\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "print(\"Random Forest Model Performance:\")\n",
    "print(f\"Train RMSE: {train_rmse_rf:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse_rf:.4f}\")\n",
    "print(f\"Train R²: {train_r2_rf:.4f}\")\n",
    "print(f\"Test R²: {test_r2_rf:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': ['DRUG_ID', 'COSMIC_ID'],\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Create scatter plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_test_pred_rf, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual z_LN_IC50', fontsize=12)\n",
    "plt.ylabel('Predicted z_LN_IC50', fontsize=12)\n",
    "plt.title('Random Forest: Actual vs Predicted Values (Test Set)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print additional statistics\n",
    "residuals_rf = y_test - y_test_pred_rf\n",
    "print(f\"\\nResiduals Statistics:\")\n",
    "print(f\"Mean Residual: {residuals_rf.mean():.4f}\")\n",
    "print(f\"Std Residual: {residuals_rf.std():.4f}\")\n",
    "print(f\"Min Residual: {residuals_rf.min():.4f}\")\n",
    "print(f\"Max Residual: {residuals_rf.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df16fcf",
   "metadata": {},
   "source": [
    "### Save Random Forest model for ln(IC50) prediction as .pkl file to be used in Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12687e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf_model, 'rf_ic50.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2f1f1",
   "metadata": {},
   "source": [
    "# Model Training for z_AUC Prediction\n",
    "\n",
    "Now we train all models to predict z_AUC instead of z_LN_IC50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd046ff0",
   "metadata": {},
   "source": [
    "### Data preparation for z_AUC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable for z_AUC prediction\n",
    "y_train_auc = train_df_random['z_AUC']\n",
    "y_test_auc = test_df_random['z_AUC']\n",
    "\n",
    "print(f\"Training samples: {len(y_train_auc)}\")\n",
    "print(f\"Test samples: {len(y_test_auc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9956076",
   "metadata": {},
   "source": [
    "### Random Forest and Hyper Parameter Tuning for z_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ee12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest for z_AUC\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, 20, None]\n",
    "}\n",
    "\n",
    "rf_base_auc = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search_rf_auc = GridSearchCV(rf_base_auc, param_grid_rf, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search_rf_auc.fit(X_train, y_train_auc)\n",
    "\n",
    "print(f\"Best params: {grid_search_rf_auc.best_params_}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(-grid_search_rf_auc.best_score_):.4f}\")\n",
    "\n",
    "rf_model_auc = grid_search_rf_auc.best_estimator_\n",
    "y_train_pred_rf_auc = rf_model_auc.predict(X_train)\n",
    "y_test_pred_rf_auc = rf_model_auc.predict(X_test)\n",
    "\n",
    "train_rmse_rf_auc = np.sqrt(mean_squared_error(y_train_auc, y_train_pred_rf_auc))\n",
    "test_rmse_rf_auc = np.sqrt(mean_squared_error(y_test_auc, y_test_pred_rf_auc))\n",
    "train_r2_rf_auc = r2_score(y_train_auc, y_train_pred_rf_auc)\n",
    "test_r2_rf_auc = r2_score(y_test_auc, y_test_pred_rf_auc)\n",
    "\n",
    "print(\"Random Forest (z_AUC):\")\n",
    "print(f\"Train RMSE: {train_rmse_rf_auc:.4f}, Test RMSE: {test_rmse_rf_auc:.4f}\")\n",
    "print(f\"Train R²: {train_r2_rf_auc:.4f}, Test R²: {test_r2_rf_auc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_auc, y_test_pred_rf_auc, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test_auc.min(), y_test_auc.max()], [y_test_auc.min(), y_test_auc.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual z_AUC', fontsize=12)\n",
    "plt.ylabel('Predicted z_AUC', fontsize=12)\n",
    "plt.title('Random Forest: z_AUC Prediction', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d092760",
   "metadata": {},
   "source": [
    "### Save Random Forest model for z_AUC prediction as .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_model_auc, 'rf_auc.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0f6a7",
   "metadata": {},
   "source": [
    "# Model Training for y_weighted_0.25 Prediction\n",
    "\n",
    "Now we train all models to predict y_weighted_0.25 (weighted combination: 0.25 * z_LN_IC50 + 0.75 * z_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a6590",
   "metadata": {},
   "source": [
    "### Data preparation for y_weighted_0.25 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable for y_weighted_0.25 prediction\n",
    "y_train_weighted = train_df_random['y_weighted_0.25']\n",
    "y_test_weighted = test_df_random['y_weighted_0.25']\n",
    "\n",
    "print(f\"Training samples: {len(y_train_weighted)}\")\n",
    "print(f\"Test samples: {len(y_test_weighted)}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"Mean: {y_train_weighted.mean():.4f}\")\n",
    "print(f\"Std: {y_train_weighted.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1516b51",
   "metadata": {},
   "source": [
    "### Random Forest and Hyper Parameter tuning for y_weighted_0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest for y_weighted_0.25\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, 20, None]\n",
    "}\n",
    "\n",
    "rf_base_weighted = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search_rf_weighted = GridSearchCV(rf_base_weighted, param_grid_rf, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search_rf_weighted.fit(X_train, y_train_weighted)\n",
    "\n",
    "print(f\"Best params: {grid_search_rf_weighted.best_params_}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(-grid_search_rf_weighted.best_score_):.4f}\")\n",
    "\n",
    "rf_model_weighted = grid_search_rf_weighted.best_estimator_\n",
    "y_train_pred_rf_weighted = rf_model_weighted.predict(X_train)\n",
    "y_test_pred_rf_weighted = rf_model_weighted.predict(X_test)\n",
    "\n",
    "train_rmse_rf_weighted = np.sqrt(mean_squared_error(y_train_weighted, y_train_pred_rf_weighted))\n",
    "test_rmse_rf_weighted = np.sqrt(mean_squared_error(y_test_weighted, y_test_pred_rf_weighted))\n",
    "train_r2_rf_weighted = r2_score(y_train_weighted, y_train_pred_rf_weighted)\n",
    "test_r2_rf_weighted = r2_score(y_test_weighted, y_test_pred_rf_weighted)\n",
    "\n",
    "print(\"Random Forest (y_weighted_0.25):\")\n",
    "print(f\"Train RMSE: {train_rmse_rf_weighted:.4f}, Test RMSE: {test_rmse_rf_weighted:.4f}\")\n",
    "print(f\"Train R²: {train_r2_rf_weighted:.4f}, Test R²: {test_r2_rf_weighted:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_weighted, y_test_pred_rf_weighted, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test_weighted.min(), y_test_weighted.max()], [y_test_weighted.min(), y_test_weighted.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual y_weighted_0.25', fontsize=12)\n",
    "plt.ylabel('Predicted y_weighted_0.25', fontsize=12)\n",
    "plt.title('Random Forest: y_weighted_0.25 Prediction', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db012e5",
   "metadata": {},
   "source": [
    "# Model Training for Sensitivity Prediction\n",
    "\n",
    "Now we train all models to predict sensitivity (average of z_IC50_sens and z_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c0e1b",
   "metadata": {},
   "source": [
    "### Data preparation for sensitivity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable for sensitivity prediction\n",
    "y_train_sens = train_df_random['sensitivity']\n",
    "y_test_sens = test_df_random['sensitivity']\n",
    "\n",
    "print(f\"Training samples: {len(y_train_sens)}\")\n",
    "print(f\"Test samples: {len(y_test_sens)}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"Mean: {y_train_sens.mean():.4f}\")\n",
    "print(f\"Std: {y_train_sens.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9cec66",
   "metadata": {},
   "source": [
    "### Random Forest and Hyper Parameter Tuning for sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff066cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest for sensitivity\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, 20, None]\n",
    "}\n",
    "\n",
    "rf_base_sens = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search_rf_sens = GridSearchCV(rf_base_sens, param_grid_rf, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search_rf_sens.fit(X_train, y_train_sens)\n",
    "\n",
    "print(f\"Best params: {grid_search_rf_sens.best_params_}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(-grid_search_rf_sens.best_score_):.4f}\")\n",
    "\n",
    "rf_model_sens = grid_search_rf_sens.best_estimator_\n",
    "y_train_pred_rf_sens = rf_model_sens.predict(X_train)\n",
    "y_test_pred_rf_sens = rf_model_sens.predict(X_test)\n",
    "\n",
    "train_rmse_rf_sens = np.sqrt(mean_squared_error(y_train_sens, y_train_pred_rf_sens))\n",
    "test_rmse_rf_sens = np.sqrt(mean_squared_error(y_test_sens, y_test_pred_rf_sens))\n",
    "train_r2_rf_sens = r2_score(y_train_sens, y_train_pred_rf_sens)\n",
    "test_r2_rf_sens = r2_score(y_test_sens, y_test_pred_rf_sens)\n",
    "\n",
    "print(\"Random Forest (sensitivity):\")\n",
    "print(f\"Train RMSE: {train_rmse_rf_sens:.4f}, Test RMSE: {test_rmse_rf_sens:.4f}\")\n",
    "print(f\"Train R²: {train_r2_rf_sens:.4f}, Test R²: {test_r2_rf_sens:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_sens, y_test_pred_rf_sens, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test_sens.min(), y_test_sens.max()], [y_test_sens.min(), y_test_sens.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual sensitivity', fontsize=12)\n",
    "plt.ylabel('Predicted sensitivity', fontsize=12)\n",
    "plt.title('Random Forest: sensitivity Prediction', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_model_sens, 'rf_sens.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e76557",
   "metadata": {},
   "source": [
    "## Model Performance Summary\n",
    "\n",
    "Comparison of Random Forest for all target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary table for Random Forest only\n",
    "summary_data = {\n",
    "    'Target': ['z_LN_IC50', 'z_AUC', 'y_weighted_0.25', 'sensitivity'],\n",
    "    'Train RMSE': [\n",
    "        train_rmse_rf,\n",
    "        train_rmse_rf_auc,\n",
    "        train_rmse_rf_weighted,\n",
    "        train_rmse_rf_sens\n",
    "    ],\n",
    "    'Test RMSE': [\n",
    "        test_rmse_rf,\n",
    "        test_rmse_rf_auc,\n",
    "        test_rmse_rf_weighted,\n",
    "        test_rmse_rf_sens\n",
    "    ],\n",
    "    'Train R²': [\n",
    "        train_r2_rf,\n",
    "        train_r2_rf_auc,\n",
    "        train_r2_rf_weighted,\n",
    "        train_r2_rf_sens\n",
    "    ],\n",
    "    'Test R²': [\n",
    "        test_r2_rf,\n",
    "        test_r2_rf_auc,\n",
    "        test_r2_rf_weighted,\n",
    "        test_r2_rf_sens\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Round values for better readability\n",
    "summary_df['Train RMSE'] = summary_df['Train RMSE'].round(4)\n",
    "summary_df['Test RMSE'] = summary_df['Test RMSE'].round(4)\n",
    "summary_df['Train R²'] = summary_df['Train R²'].round(4)\n",
    "summary_df['Test R²'] = summary_df['Test R²'].round(4)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RANDOM FOREST MODEL PERFORMANCE SUMMARY - Random Split\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(summary_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Find best performing target\n",
    "best_target = summary_df.loc[summary_df['Test RMSE'].idxmin()]\n",
    "print(\"=\" * 80)\n",
    "print(\"BEST PERFORMING TARGET (Based on Test RMSE):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Target: {best_target['Target']}\")\n",
    "print(f\"Test RMSE: {best_target['Test RMSE']:.4f}\")\n",
    "print(f\"Test R²: {best_target['Test R²']:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0211a",
   "metadata": {},
   "source": [
    "### Convert pkl files to onnx for environment compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72022cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# load existing sklearn model\n",
    "rf_ic50 = joblib.load(\"../rf_ic50.pkl\")  \n",
    "initial_type = [('input', FloatTensorType([None, 2]))]\n",
    "\n",
    "# convert to ONNX\n",
    "onnx_model = convert_sklearn(rf_ic50, initial_types=initial_type)\n",
    "\n",
    "# save ONNX model\n",
    "with open(\"rf_ic50.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing sklearn model\n",
    "rf_auc = joblib.load(\"../rf_auc.pkl\")  \n",
    "initial_type = [('input', FloatTensorType([None, 2]))]\n",
    "\n",
    "# convert to ONNX\n",
    "onnx_model = convert_sklearn(rf_auc, initial_types=initial_type)\n",
    "\n",
    "# save ONNX model\n",
    "with open(\"rf_auc.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing sklearn model\n",
    "rf_sens = joblib.load(\"../rf_sens.pkl\")  \n",
    "initial_type = [('input', FloatTensorType([None, 2]))]\n",
    "\n",
    "# convert to ONNX\n",
    "onnx_model = convert_sklearn(rf_sens, initial_types=initial_type)\n",
    "\n",
    "# save ONNX model\n",
    "with open(\"rf_sens.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ps-train)",
   "language": "python",
   "name": "ps-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
